{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd1d6344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import FloatTensor\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# torchvision: popular datasets, model architectures, \n",
    "# and common image transformations for computer vision.\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from random import randint\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label_1, label_2 = 4, 9\n",
    "\n",
    "# MNIST training data\n",
    "train_set = datasets.MNIST(root='./mnist_data/', \n",
    "                           train=True, \n",
    "                           transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# Use data with two labels\n",
    "idx = (train_set.targets == label_1) + (train_set.targets == label_2)\n",
    "train_set.data = train_set.data[idx]\n",
    "train_set.targets = train_set.targets[idx]\n",
    "train_set.targets[train_set.targets == label_1] = -1\n",
    "train_set.targets[train_set.targets == label_2] = 1\n",
    "\n",
    "# MNIST testing data\n",
    "test_set = datasets.MNIST(root='./mnist_data/', \n",
    "                          train=False, transform=transforms.ToTensor())\n",
    "\n",
    "# Use data with two labels\n",
    "idx = (test_set.targets == label_1) + (test_set.targets == label_2)\n",
    "test_set.data = test_set.data[idx]\n",
    "test_set.targets = test_set.targets[idx]\n",
    "test_set.targets[test_set.targets == label_1] = -1\n",
    "test_set.targets[test_set.targets == label_2] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cf2dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(nn.Module) :\n",
    "    # MNIST data is 28x28 images\n",
    "    def __init__(self, input_dim=28*28) :\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        return self.linear(x.float().view(-1, 28*28))\n",
    "\n",
    "\n",
    "model_with_SOQ_loss = LR()\n",
    "model_with_KLDiv_loss = LR()\n",
    "\n",
    "def sum_of_squares(output, target):\n",
    "    output = FloatTensor(output)\n",
    "    target = target.unsqueeze(-1)\n",
    "    result = torch.mean(0.5*(1-target)*( \n",
    "        (1-torch.sigmoid(-output))**2 + (torch.sigmoid(output))**2 )\n",
    "                + 0.5*(1+target)*( (1-torch.sigmoid(output))**2 \n",
    "                                  + (torch.sigmoid(-output))**2 ))\n",
    "\n",
    "    return result\n",
    "\n",
    "def logistic_loss(output, target):\n",
    "\n",
    "    return torch.mean(-torch.nn.functional.logsigmoid(\n",
    "        target.reshape(-1)*output.reshape(-1)))\n",
    "\n",
    "\n",
    "loss_function_1 = sum_of_squares\n",
    "loss_function_2 = logistic_loss\n",
    "\n",
    "optimizer_1 = torch.optim.SGD(model_with_SOQ_loss.parameters(), \n",
    "                              lr=255*1e-4)\n",
    "\n",
    "optimizer_2 = torch.optim.SGD(model_with_KLDiv_loss.parameters(), \n",
    "                              lr=255*1e-4)\n",
    "\n",
    "batch_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "558c2c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time ellapsed in training is: 6.977036237716675\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset=train_set, batch_size= batch_size , shuffle=True)\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "iter_count = 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for image,label in train_loader :\n",
    "        iter_count += 1\n",
    "        if iter_count > 1000:\n",
    "            break\n",
    "\n",
    "        # Clear previously computed gradient\n",
    "        optimizer_1.zero_grad()\n",
    "        optimizer_2.zero_grad()\n",
    "\n",
    "        # then compute gradient with forward and backward passes\n",
    "        train_loss = loss_function_1(\n",
    "            model_with_SOQ_loss(image), label.float())\n",
    "        \n",
    "        train_loss_2 = loss_function_2(\n",
    "            model_with_KLDiv_loss(image), label.float())\n",
    "        \n",
    "        train_loss.backward()\n",
    "        train_loss_2.backward()\n",
    "\n",
    "        # perform SGD step (parameter update)\n",
    "        optimizer_1.step()\n",
    "        optimizer_2.step()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time ellapsed in training is: {end-start}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47f0db2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Using Sum of Squares as loss_func ----\n",
      "[Test set] Average loss: 0.0840, Accuracy: 1909/1991 (95.88%)\n",
      "\n",
      "---- Using KL Divergence as loss_func ----\n",
      "[Test set] Average loss: 0.1457, Accuracy: 1905/1991 (95.68%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, correct = 0, 0\n",
    "test_loss_2, correct_2 = 0, 0\n",
    "misclassified_ind = []\n",
    "correct_ind = []\n",
    "misclassified_ind_2 = []\n",
    "correct_ind_2 = []\n",
    "\n",
    "# Test data\n",
    "test_loader = DataLoader(dataset=test_set, \n",
    "                         batch_size=1, shuffle=False)\n",
    "# no need to shuffle test data\n",
    "\n",
    "# Evaluate accuracy using test data\n",
    "for ind, (image, label) in enumerate(test_loader) :\n",
    "\n",
    "    # Forward pass\n",
    "    output = model_with_SOQ_loss(image)\n",
    "    output2 = model_with_KLDiv_loss(image)\n",
    "\n",
    "    # Calculate cumulative loss\n",
    "    test_loss += loss_function_1(output, \n",
    "                                 label.float()).item()\n",
    "    \n",
    "    test_loss_2 += loss_function_2(output2, \n",
    "                                   label.float()).item()\n",
    "\n",
    "    # Make a prediction\n",
    "    if output.item() * label.item() >= 0 :\n",
    "        correct += 1\n",
    "        correct_ind += [ind]\n",
    "    else:\n",
    "        misclassified_ind += [ind]\n",
    "\n",
    "    # Make a prediction\n",
    "    if output2.item() * label.item() >= 0 :\n",
    "        correct_2 += 1\n",
    "        correct_ind_2 += [ind]\n",
    "    else:\n",
    "        misclassified_ind_2 += [ind]\n",
    "\n",
    "# Print out the results\n",
    "print('---- Using Sum of Squares as loss_func ----')\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss /len(test_loader), correct, len(test_loader),\n",
    "        100. * correct / len(test_loader)))\n",
    "print('---- Using KL Divergence as loss_func ----')\n",
    "print('[Test set] Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss_2 /len(test_loader), correct_2, len(test_loader),\n",
    "        100. * correct_2 / len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b971159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
